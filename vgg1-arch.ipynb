{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data.npy', 'labels.npy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "13b983dd7609fa2a5af4f7c076b1f8956e59b0d5"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "class MiniVGG:\n",
    "    @staticmethod\n",
    "    def build(width,height,depth,classes):\n",
    "        model=Sequential()\n",
    "        inputS=(height,width,depth)\n",
    "        chanDim=-1\n",
    "        if(K.image_data_format()==\"channels_first\"):\n",
    "            inputS=(depth,height,width)\n",
    "            chanDim=-1\n",
    "        model.add(Conv2D(32,(3,3),padding=\"same\",input_shape=inputS))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(32,(3,3),padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64,(3,3),padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c2f51f40219ce882f71d5d899cfafaeafb51038f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\r\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\r\n",
      "Building wheels for collected packages: imutils\r\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/b2/40/59/139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\r\n",
      "Successfully built imutils\r\n",
      "Installing collected packages: imutils\r\n",
      "Successfully installed imutils-0.5.2\r\n",
      "Load images' NPY file\n",
      "Compiling model...\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Training network\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/16\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 0.8508 - acc: 0.7644 - val_loss: 1.8057 - val_acc: 0.6523\n",
      "Epoch 2/16\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.5429 - acc: 0.7800 - val_loss: 0.7664 - val_acc: 0.7240\n",
      "Epoch 3/16\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.5111 - acc: 0.7881 - val_loss: 1.8651 - val_acc: 0.6039\n",
      "Epoch 4/16\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.5054 - acc: 0.7926 - val_loss: 0.8842 - val_acc: 0.7832\n",
      "Epoch 5/16\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4896 - acc: 0.7899 - val_loss: 0.6108 - val_acc: 0.7330\n",
      "Epoch 6/16\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4700 - acc: 0.7887 - val_loss: 0.4932 - val_acc: 0.7993\n",
      "Epoch 7/16\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4409 - acc: 0.7968 - val_loss: 0.5113 - val_acc: 0.7599\n",
      "Epoch 8/16\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4052 - acc: 0.8215 - val_loss: 0.3886 - val_acc: 0.8136\n",
      "Epoch 9/16\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4028 - acc: 0.8200 - val_loss: 0.4985 - val_acc: 0.7545\n",
      "Epoch 10/16\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4220 - acc: 0.8082 - val_loss: 0.3489 - val_acc: 0.8387\n",
      "Epoch 11/16\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.4283 - acc: 0.8067 - val_loss: 0.6610 - val_acc: 0.6129\n",
      "Epoch 12/16\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.4334 - acc: 0.7956 - val_loss: 0.7277 - val_acc: 0.5591\n",
      "Epoch 13/16\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.3633 - acc: 0.8341 - val_loss: 0.6542 - val_acc: 0.6470\n",
      "Epoch 14/16\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4016 - acc: 0.8212 - val_loss: 0.3625 - val_acc: 0.8351\n",
      "Epoch 15/16\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.4270 - acc: 0.7908 - val_loss: 0.4569 - val_acc: 0.7903\n",
      "Epoch 16/16\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.3873 - acc: 0.8272 - val_loss: 0.3545 - val_acc: 0.8530\n",
      "Save the model for the applied CNN\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85       279\n",
      "           1       0.82      0.90      0.86       279\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       558\n",
      "   macro avg       0.86      0.85      0.85       558\n",
      "weighted avg       0.86      0.85      0.85       558\n",
      "\n",
      "[[225  54]\n",
      " [ 28 251]]\n",
      "acc: 0.8530\n",
      "sensitivity: 0.8065\n",
      "specificity: 0.8996\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from project.unet import Unet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from keras import backend as K\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 16\n",
    "INIT_LR = 1e-3 #Initial Learning rate\n",
    "BS = 32 # Bach size to feed\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"Load images' NPY file\")\n",
    "data = []\n",
    "labels = []\n",
    "# grab the image paths and randomly shuffle them\n",
    "random.seed(42)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "data=np.load('../input/data.npy')\n",
    "labels=np.load('../input/labels.npy')\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=6)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the model\n",
    "print(\"Compiling model...\")\n",
    "model = MiniVGG.build(width=128, height=128, depth=3, classes=2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS) #Optimise uisng Adam \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    \n",
    "# train the network\n",
    "print(\"Training network\")\n",
    "#checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX)//BS,\n",
    "\tepochs=EPOCHS, verbose=1,callbacks=[tensorboard])\n",
    "\n",
    "label_name=[\"benign\",\"malicious\"]\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "print(\"Save the model for the applied CNN\")\n",
    "#model.save(args[\"model.hdf5\"])\n",
    "\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=128) #Check this\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "predictions.argmax(axis=1)))\n",
    "\n",
    "cm = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1))\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "print(cm)\n",
    "print(\"acc: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a80b97d20d2ee08846612dac0357afd7e8029a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-25 19:19:03--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 52.202.60.111, 52.21.103.149, 52.45.111.123, ...\r\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|52.202.60.111|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13584026 (13M) [application/octet-stream]\r\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\r\n",
      "\r\n",
      "ngrok-stable-linux- 100%[===================>]  12.95M  18.1MB/s    in 0.7s    \r\n",
      "\r\n",
      "2019-03-25 19:19:04 (18.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13584026/13584026]\r\n",
      "\r\n",
      "Archive:  ngrok-stable-linux-amd64.zip\r\n",
      "  inflating: ngrok                   \r\n",
      "http://0d7a9d6f.ngrok.io\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "LOG_DIR = './logs' # Here you have to put your log directory\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a778bdf4f914824bbed4fe0ceea9e6a41e2a0309"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
