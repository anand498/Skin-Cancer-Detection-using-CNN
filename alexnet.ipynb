{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data.npy', 'labels.npy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class alexnet:\n",
    "    @staticmethod\n",
    "    def build(width,height,depth,classes):\n",
    "        model=Sequential()\n",
    "        inputS=(height,width,depth)\n",
    "        chanDim=-1\n",
    "        if(K.image_data_format()==\"channels_first\"):\n",
    "            inputS=(depth,height,width)\n",
    "            chanDim=1\n",
    "\n",
    "        model.add(Conv2D(filters=128, input_shape=inputS, kernel_size=(4,4), padding='valid'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "        model.add(Conv2D(filters=256, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "        model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, input_shape=(128*128*3,)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(4096))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1000))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0ba211d5a4c6ec815c986e597aeb82703cf62175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\r\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\r\n",
      "Building wheels for collected packages: imutils\r\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/b2/40/59/139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\r\n",
      "Successfully built imutils\r\n",
      "Installing collected packages: imutils\r\n",
      "Successfully installed imutils-0.5.2\r\n",
      "Load images' NPY file\n",
      "Compiling model...\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Training network\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/32\n",
      "52/52 [==============================] - 12s 222ms/step - loss: 7.8836 - acc: 0.4982 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 2/32\n",
      "52/52 [==============================] - 8s 150ms/step - loss: 8.0898 - acc: 0.4953 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 3/32\n",
      "52/52 [==============================] - 8s 149ms/step - loss: 7.9742 - acc: 0.5026 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 4/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.1669 - acc: 0.4905 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 5/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.9597 - acc: 0.5035 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 6/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.0368 - acc: 0.4987 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 7/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.8778 - acc: 0.5086 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 8/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.9211 - acc: 0.5059 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 9/32\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 7.9790 - acc: 0.5023 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 10/32\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 8.1380 - acc: 0.4923 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 11/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.7477 - acc: 0.5167 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 12/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.2440 - acc: 0.4857 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 13/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.8778 - acc: 0.5086 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 14/32\n",
      "52/52 [==============================] - 8s 150ms/step - loss: 8.2103 - acc: 0.4878 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 15/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.0175 - acc: 0.4999 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 16/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.0706 - acc: 0.4965 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 17/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.0850 - acc: 0.4956 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 18/32\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 7.8152 - acc: 0.5125 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 19/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.9452 - acc: 0.5044 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 20/32\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 7.7766 - acc: 0.5149 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 21/32\n",
      "52/52 [==============================] - 8s 153ms/step - loss: 8.1043 - acc: 0.4944 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 22/32\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 7.9453 - acc: 0.5044 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 23/32\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 8.2826 - acc: 0.4833 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 24/32\n",
      "52/52 [==============================] - 8s 157ms/step - loss: 8.0320 - acc: 0.4989 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 25/32\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 8.1187 - acc: 0.4935 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 26/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.6609 - acc: 0.5221 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 27/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.1091 - acc: 0.4941 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 28/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 8.1814 - acc: 0.4896 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 29/32\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 7.9163 - acc: 0.5062 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 30/32\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 8.1428 - acc: 0.4920 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 31/32\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 7.8441 - acc: 0.5107 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 32/32\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 7.9115 - acc: 0.5065 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Save the model for the applied CNN\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       279\n",
      "           1       0.00      0.00      0.00       279\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       558\n",
      "   macro avg       0.25      0.50      0.33       558\n",
      "weighted avg       0.25      0.50      0.33       558\n",
      "\n",
      "[[279   0]\n",
      " [279   0]]\n",
      "acc: 0.5000\n",
      "sensitivity: 1.0000\n",
      "specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from keras import backend as K\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "EPOCHS = 32\n",
    "INIT_LR = 1e-3 #Initial Learning rate\n",
    "BS = 32 # Bach size to feed\n",
    "\n",
    "print(\"Load images' NPY file\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "data=np.load('../input/data.npy')\n",
    "labels=np.load('../input/labels.npy')\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=6)\n",
    "\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True, fill_mode=\"nearest\") \n",
    "\n",
    "print(\"Compiling model...\")\n",
    "model = alexnet.build(128,128,3,2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS) \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Training network\")\n",
    "\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX)//BS,\n",
    "\tepochs=EPOCHS, verbose=1,callbacks=[tensorboard])\n",
    "\n",
    "label_name=[\"benign\",\"malicious\"]\n",
    "\n",
    "\n",
    "print(\"Save the model for the applied CNN\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=128) #Check this\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "predictions.argmax(axis=1)))\n",
    "\n",
    "cm = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1))\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "print(cm)\n",
    "print(\"acc: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "86861c70dacb67f0e89fd20e1f6a3e8adcb20002"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b75f924519dde3bd42c7c031012d1e201ab46b60"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
